{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksTZ5pAtXWXh"
      },
      "source": [
        "# Setup\n",
        "-  Follow the setup instructions based on your preferred environment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdhQJTlgXWXk"
      },
      "source": [
        "## Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvlykMP_XWXl"
      },
      "source": [
        "One of our key goals in designing this assignment is to allow you to complete most of the preliminary implementation work locally.  \n",
        "We highly recommend that you **pass all tests locally** using the provided `hw4_data_subset` before moving to a GPU runtime.  \n",
        "To do this, simply:\n",
        "\n",
        "### Create a new conda environment\n",
        "```bash\n",
        "# Be sure to deactivate any active environments first\n",
        "conda create -n hw4 python=3.12.4\n",
        "```\n",
        "\n",
        "### Activate the conda environment\n",
        "```bash\n",
        "conda activate hw4\n",
        "```\n",
        "\n",
        "### Install the dependencies using the provided `requirements.txt`\n",
        "```bash\n",
        "pip install --no-cache-dir --ignore-installed -r requirements.txt\n",
        "```\n",
        "\n",
        "### Ensure that your notebook is in the same working directory as the `Handout`\n",
        "This can be achieved by:\n",
        "1. Physically moving the notebook into the handout directory.\n",
        "2. Changing the notebookâ€™s current working directory to the handout directory using the os.chdir() function.\n",
        "\n",
        "### Open the notebook and select the newly created environment from the kernel selector.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "â”œâ”€â”€ README.md\n",
        "â”œâ”€â”€ requirements.txt\n",
        "â”œâ”€â”€ hw4lib/\n",
        "â”œâ”€â”€ mytorch/\n",
        "â”œâ”€â”€ tests/\n",
        "â””â”€â”€ hw4_data_subset/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1K8ZJzQXWXm"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zBCpeYGXWXm"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CEuLMiFXWXm"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"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\"\n",
        "\n",
        "GITHUB_USERNAME = \"puru-samal\"\n",
        "REPO_NAME       = \"IDL-HW4\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ov_XzmaXWXn"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MczkQoLuXWXo"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- `NOTE`: Your runtime will be restarted to ensure all dependencies are updated.\n",
        "- `NOTE`: You will see a runtime crashed message, this was intentionally done. Simply move on to the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GVyqU62HXWXo"
      },
      "outputs": [],
      "source": [
        "%pip install --no-deps -r IDL-HW4/requirements.txt\n",
        "import os\n",
        "os.kill(os.getpid(), 9) # NOTE: This will restart the your colab Python runtime (required)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vece1tMZXWXo"
      },
      "source": [
        "### Step 3: Authenticate Kaggle\n",
        "In order to use the Kaggleâ€™s public API, you must first authenticate using an API token. Go to the 'Account' tab of your user profile and select 'Create New Token'. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "- `TODO`: Set your kaggle username and api key here based on the API credentials listed in the kaggle.json\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vympB_RoXWXo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"cmu11785\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"c794008216f859650cc3e292757b79b6\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dww5UXpXWXp"
      },
      "source": [
        "### Step 4: Obtain Data\n",
        "\n",
        "- `NOTE`: This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfPpo9nlXWXp"
      },
      "outputs": [],
      "source": [
        "!curl -L -o /content/s25-hw4-data.zip https://www.kaggle.com/api/v1/datasets/download/cmu11785/s25-hw4-data\n",
        "!unzip -q -o /content/s25-hw4-data.zip -d /content/hw4_data\n",
        "!rm -rf /content/s25-hw4-data.zip\n",
        "!du -h --max-depth=2 /content/hw4_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV797kwAXWXp"
      },
      "source": [
        "### Step 5: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "â”œâ”€â”€ README.md\n",
        "â”œâ”€â”€ requirements.txt\n",
        "â”œâ”€â”€ hw4lib/\n",
        "â”œâ”€â”€ mytorch/\n",
        "â”œâ”€â”€ tests/\n",
        "â””â”€â”€ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQOe2uDxXWXp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqzcpqG0XWXp"
      },
      "source": [
        "## Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEg4SBYUXWXq"
      },
      "source": [
        "While it is possible to run the notebook on Kaggle, we would recommend against it. This assignment is more resource intensive and may run slower on Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMX5lqH9XWXq"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qDr7vrLXWXq"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"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\"\n",
        "\n",
        "GITHUB_USERNAME = \"puru-samal\"\n",
        "REPO_NAME       = \"IDL-HW4\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_CXP-GvXWXr"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2nQNvB9XWXr"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- Simply set the `Environment` setting in the notebook to `Always use latest environment`. No need to install anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIj4qFt0XWXr"
      },
      "source": [
        "### Step 3: Authenticate Kaggle\n",
        "In order to use the Kaggleâ€™s public API, you must first authenticate using an API token. Go to the 'Account' tab of your user profile and select 'Create New Token'. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "- `TODO`: Set your kaggle username and api key here based on the API credentials listed in the kaggle.json\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKffbcjnXWXr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"cmu1178\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"c794008216f859650cc3e292757b79b6\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIu_QszEXWXr"
      },
      "source": [
        "### Step 4: Obtain Data\n",
        "\n",
        "#### âš ï¸ Important: Kaggle Users  \n",
        "If you are using Kaggle, **do not manually download the data!** The dataset is large and may exceed your available disk space. Instead, follow these steps to add the dataset directly to your notebook:\n",
        "\n",
        "1. Open your **Kaggle Notebook**.  \n",
        "2. Navigate to **Notebook â†’ Input**.  \n",
        "3. Click **Add Input**.  \n",
        "4. In the search bar, paste the following URL:  \n",
        "   ðŸ‘‰ [https://www.kaggle.com/datasets/cmu11785/s25-hw4-data](https://www.kaggle.com/datasets/cmu11785/s25-hw4-data)  \n",
        "5. Click the **âž• (plus sign)** to add the dataset to your notebook.  \n",
        "\n",
        "#### ðŸ“Œ Note:  \n",
        "This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eylVaaxrXWXr"
      },
      "source": [
        "### Step 5: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "â”œâ”€â”€ README.md\n",
        "â”œâ”€â”€ requirements.txt\n",
        "â”œâ”€â”€ hw4lib/\n",
        "â”œâ”€â”€ mytorch/\n",
        "â”œâ”€â”€ tests/\n",
        "â””â”€â”€ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wpjv3ujXWXs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP0Aucc7XWXs"
      },
      "source": [
        "## PSC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJm_aSHvXWXs"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches.\n",
        "- If you use Remote - SSH to connect to Bridges2, you can upload the handout to your project directory and work from there.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "simQXvJoXWXs"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"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\"\n",
        "\n",
        "GITHUB_USERNAME = \"puru-samal\"\n",
        "REPO_NAME       = \"IDL-HW4\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ibi0yUFXWXs"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXhjLh83XWXt"
      },
      "source": [
        "### Step 2: Setting Up Your Environment on Bridges2\n",
        "\n",
        "For this homework, we are providing a shared Conda environment for the entire class. Follow these steps to set up the environment and start a Jupyter notebook on Bridges2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG_taa71XWXt"
      },
      "source": [
        "#### 1. SSH into Bridges2\n",
        "```bash\n",
        "ssh username@bridges2.psc.edu\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hpcW2C5XWXt"
      },
      "source": [
        "#### 2. Navigate to your Project Directory\n",
        "```bash\n",
        "cd $PROJECT\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-YNBIVWXWXt"
      },
      "source": [
        "#### 3. Load the Anaconda Module\n",
        "```bash\n",
        "module load anaconda3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-7_f2PGXWXt"
      },
      "source": [
        "#### 4. Activate the provided HW4 Environment\n",
        "```bash\n",
        "conda deactivate # First, deactivate any existing Conda environment\n",
        "conda activate /jet/home/psamal/hw_envs/idl_hw4\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag3zHpx2XWXu"
      },
      "source": [
        "#### 5. Request a Compute Node\n",
        "```bash\n",
        "interact -p GPU-shared --gres=gpu:v100-32:1 -t 8:00:00\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "annERewlXWXu"
      },
      "source": [
        "#### 6. Re-activate Environment\n",
        "If your Conda environment was deactivated due to node allocation:\n",
        "```bash\n",
        "conda deactivate # First, deactivate any existing Conda environment\n",
        "conda activate /jet/home/psamal/hw_envs/idl_hw4\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPp6QNFGXWXu"
      },
      "source": [
        "#### 7. Start Jupyter Notebook\n",
        "Launch Jupyter Notebook:\n",
        "```bash\n",
        "jupyter notebook --no-browser --ip=0.0.0.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9QqEXMkXWXv"
      },
      "source": [
        "\n",
        "#### 8. Connect to Jupyter Server\n",
        "\n",
        "You can now use your prefered way of connecting to the Jupyter Server. Your options should be covered in the docs linked in post 558 @ piazza.\n",
        "\n",
        "The following is my preferred way of connecting to the Jupyter Server:\n",
        "\n",
        "##### 8.1 Connect in VSCode\n",
        "I prefer uploading the notebook to PSC Bridges2 storage ($PROJECT directory) and then connecting to the Jupyter Server from there.\n",
        "1. Use Remote - SSH to connect to Bridges2 and navigate to your project directory.\n",
        "2. Upload the notebook to the project directory.\n",
        "3. Open the notebook in VSCode.\n",
        "4. Go to **Kernel** â†’ **Select Another Kernel** â†’ **Existing Jupyter Server**\n",
        "5. Enter the URL of the Jupyter Server:```http://{hostname}:{port}/tree?token={token}```\n",
        "   - eg: `http://v011.ib.bridges2.psc.edu:8888/tree?token=e4b302434e68990f28bc2b4ae8d216eb87eecb7090526249`\n",
        "\n",
        "> **Note**: Replace `{hostname}`, `{port}` and `{token}` with your actual values from the Jupyter output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9HnVDXFXWXv"
      },
      "source": [
        "### Step 3: Authenticate Kaggle\n",
        "In order to use the Kaggleâ€™s public API, you must first authenticate using an API token. Go to the 'Account' tab of your user profile and select 'Create New Token'. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "- `TODO`: Set your kaggle username and api key here based on the API credentials listed in the kaggle.json\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvZCfcK6XWXw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"cmu1178\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"c794008216f859650cc3e292757b79b6\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTzqOnqVXWXw"
      },
      "source": [
        "### Step 4: Get Data\n",
        "- `NOTE`: This will download and unzip data for both `HW4P1` and `HW4P2`\n",
        "- `NOTE`: We are using `$LOCAL`: the scratch storage on local disk on the node running a job to store out data.\n",
        "  - Disk accesses are much faster than what you would get from `$PROJECT` storage\n",
        "  - `IT IS NOT PERSISTENT`\n",
        "- `NOTE`: Make sure you have completed the previous steps before running this cell.\n",
        "- Read more about it PSC File Spaces [here](https://www.psc.edu/resources/bridges-2/user-guide#file-spaces)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx2lB7TKXWXw"
      },
      "outputs": [],
      "source": [
        "!curl -L -o $LOCAL/s25-hw4-data.zip https://www.kaggle.com/api/v1/datasets/download/cmu11785/s25-hw4-data\n",
        "!unzip -q -o $LOCAL/s25-hw4-data.zip -d $LOCAL/hw4_data\n",
        "!rm -rf $LOCAL/s25-hw4-data.zip\\\n",
        "!du -h --max-depth=2 $LOCAL/hw4_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbFIgoFyXWXw"
      },
      "source": [
        "### Step 5: Move to Handout Directory\n",
        "Depending on the way you are running your notebook, you may or may not need to run this cell. As long as you are within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "â”œâ”€â”€ README.md\n",
        "â”œâ”€â”€ requirements.txt\n",
        "â”œâ”€â”€ hw4lib/\n",
        "â”œâ”€â”€ mytorch/\n",
        "â”œâ”€â”€ tests/\n",
        "â””â”€â”€ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmRtaGthXWXw"
      },
      "outputs": [],
      "source": [
        "# Move to the handout directory if you are not there already\n",
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv-iljarXWXw"
      },
      "source": [
        "# Imports\n",
        "- If your setup was done correctly, you should be able to run the following cell without any issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41s27pCAXWXx"
      },
      "outputs": [],
      "source": [
        "from hw4lib.data import (\n",
        "    H4Tokenizer,\n",
        "    ASRDataset,\n",
        "    verify_dataloader\n",
        ")\n",
        "from hw4lib.model import (\n",
        "    DecoderOnlyTransformer,\n",
        "    EncoderDecoderTransformer\n",
        ")\n",
        "from hw4lib.utils import (\n",
        "    create_scheduler,\n",
        "    create_optimizer,\n",
        "    plot_lr_schedule\n",
        ")\n",
        "from hw4lib.trainers import (\n",
        "    ASRTrainer,\n",
        "    ProgressiveTrainer\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import yaml\n",
        "import gc\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import os\n",
        "import json\n",
        "import wandb\n",
        "import pandas as pd\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ey-Nd0XWXx"
      },
      "source": [
        "# Implementations\n",
        "- `NOTE`: All of these implementations have detailed specification, implementation details, and hints in their respective source files. Make sure to read all of them in their entirety to understand the implementation details!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvQA7UchXWXx"
      },
      "source": [
        "## Dataset Implementation\n",
        "- Implement the `ASRDataset` class in `hw4lib/data/asr_dataset.py`.\n",
        "- You will have to implement parts of `__init__` and completely implement the `__len__`, `__getitem__` and `collate_fn` methods.\n",
        "- Run the cell below to check your implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPZNGGJ9XWXx"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_dataset_asr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKyK49VXWXx"
      },
      "source": [
        "## Model Implementations\n",
        "\n",
        "Overview:\n",
        "\n",
        "- Implement the `CrossAttentionLayer` class in `hw4lib/model/sublayers.py`.\n",
        "- Implement the `CrossAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Implement the `SelfAttentionEncoderLayer` class in `hw4lib/model/encoder_layers.py`. This will be mostly a copy-paste of the `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py` with one minor diffrence: it can attend to all positions in the input sequence.\n",
        "- Implement the `EncoderDecoderTransformer` class in `hw4lib/model/transformers.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POb3Agw6XWXy"
      },
      "source": [
        "### Transformer Sublayers\n",
        "- Now, Implement the `CrossAttentionLayer` class in `hw4lib/model/sublayers.py`.\n",
        "- `NOTE`: You should have already implemented the `SelfAttentionLayer`, and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Run the cell below to check your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vYRTVdGXWXy"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_sublayer_crossattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbIAaQ--XWXy"
      },
      "source": [
        "### Transformer Cross-Attention Decoder Layer\n",
        "- Implement the `CrossAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Then run the cell below to check your implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Ke3vAVXWXy"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_decoderlayer_crossattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28snypxrXWXy"
      },
      "source": [
        "### Transformer Self-Attention Encoder Layer\n",
        "- Implement the `SelfAttentionEncoderLayer` class in `hw4lib/model/encoder_layers.py`.\n",
        "- Then run the cell below to check your implementation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_bRj56mXWXy"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_encoderlayer_selfattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1b9Co8HXWXy"
      },
      "source": [
        "### Encoder-Decoder Transformer\n",
        "\n",
        "- Implement the  `EncoderDecoderTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Then run the cell below to check your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ACVZWXrXWXy"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_transformer_encoder_decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxMaLdHdXWXy"
      },
      "source": [
        "## Decoding Implementation\n",
        "- We highly recommend you to implement the `generate_beam` method of the `SequenceGenerator` class in `hw4lib/decoding/sequence_generator.py`.\n",
        "- Then run the cell below to check your implementation.\n",
        "- `NOTE`: This is an optional but highly recommended task for `HW4P2` to ease the journey to high cutoffs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnAQO_VHXWXy"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_decoding --mode beam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze6Ufzt2XWXy"
      },
      "source": [
        "## Trainer Implementation\n",
        "You will have to do some minor in-filling for the `ASRTrainer` class in `hw4lib/trainers/asr_trainer.py` before you can use it.\n",
        "- Fill in the `TODO`s in the `__init__`.\n",
        "- Fill in the `TODO`s in the `_train_epoch`.\n",
        "- Fill in the `TODO`s in the `recognize` method.\n",
        "- Fill in the `TODO`s in the `_validate_epoch`.\n",
        "- Fill in the `TODO`s in the `train` method.\n",
        "- Fill in the `TODO`s in the `evaluate` method.\n",
        "\n",
        "`WARNING`: There are no test's for this. Implement carefully!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8CtOMbVXWXz"
      },
      "source": [
        "# Experiments\n",
        "From this point onwards you may want to switch to a `GPU` runtime.\n",
        "- `OBJECTIVE`: Optimize your model for `CER` on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-P4qGdjXWXz"
      },
      "source": [
        "## Config\n",
        "- You can use the `config.yaml` file to set your config for your ablation study.\n",
        "\n",
        "---\n",
        "### Notes:\n",
        "\n",
        "- Set `tokenization: token_type:` to specify your desired tokenization strategy\n",
        "- You will need to set the root path to your `hw4p1_data` folder in `data: root:`. This will depend on your setup. For eg. if you are following out setup instruction:\n",
        "  - `PSC`: `\"/local/hw4_data/hw4p1_data\"`\n",
        "  - `Colab:`: `\"/content/hw4_data/hw4p1_data\"`\n",
        "  - `Kaggle:`: `\"/kaggle/input/s25-hw4-data/hw4p1_data\"`\n",
        "- There's extra configurations in the `optimizer` section which will only be relevant if you decide to use the `create_optimizer` function we've provided in `hw4lib/utils/create_optimizer.py`.\n",
        "- `BE CAREFUL` while setting numeric values. Eg. `1e-4` will get serialized to a `str` while `1.0e-4` gets serialized to float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkFcCs6VXWXz"
      },
      "outputs": [],
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "Name                      : \"Enter-Name-Here\"\n",
        "\n",
        "###### Tokenization ------------------------------------------------------------\n",
        "tokenization:\n",
        "  token_type                : \"5k\"       # [char, 1k, 5k, 10k]\n",
        "  token_map :\n",
        "      'char': 'hw4lib/data/tokenizer_jsons/tokenizer_char.json'\n",
        "      '1k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_1000.json'\n",
        "      '5k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_5000.json'\n",
        "      '10k' : 'hw4lib/data/tokenizer_jsons/tokenizer_10000.json'\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "data:\n",
        "  root                 : \"/content/hw4_data/hw4p2_data\"  # TODO: Set the root path of your data\n",
        "  train_partition      : \"train-clean-100\"  # paired text-speech for ASR pre-training\n",
        "  val_partition        : \"dev-clean\"        # paired text-speech for ASR pre-training\n",
        "  test_partition       : \"test-clean\"       # paired text-speech for ASR pre-training\n",
        "  subset               : 1.0                # Load a subset of the data (for debugging, testing, etc\n",
        "  batch_size           : 16           #\n",
        "  NUM_WORKERS          : 2            # Set to 0 for CPU\n",
        "  norm                 : 'global_mvn' # ['global_mvn', 'cepstral', 'none']\n",
        "  num_feats            : 80\n",
        "\n",
        "  ###### SpecAugment ---------------------------------------------------------------\n",
        "  specaug                   : False  # Set to True if you want to use SpecAugment\n",
        "  specaug_conf:\n",
        "    apply_freq_mask         : True\n",
        "    freq_mask_width_range   : 5\n",
        "    num_freq_mask           : 2\n",
        "    apply_time_mask         : True\n",
        "    time_mask_width_range   : 40\n",
        "    num_time_mask           : 2\n",
        "\n",
        "###### Network Specs -------------------------------------------------------------\n",
        "model: # Encoder-Decoder Transformer (HW4P2)\n",
        "  # Speech embedding parameters\n",
        "  input_dim: 80              # Speech feature dimension\n",
        "  time_reduction: 2          # Time dimension downsampling factor\n",
        "  reduction_method: 'conv'   # The source_embedding reduction method ['lstm', 'conv', 'both']\n",
        "\n",
        "  # Architecture parameters\n",
        "  d_model: 256           # Model dimension\n",
        "  num_encoder_layers: 2  # Number of encoder layers\n",
        "  num_decoder_layers: 2  # Number of decoder layers\n",
        "  num_encoder_heads: 4   # Number of encoder attention heads\n",
        "  num_decoder_heads: 4   # Number of decoder attention heads\n",
        "  d_ff_encoder: 1024     # Feed-forward dimension for encoder\n",
        "  d_ff_decoder: 1024     # Feed-forward dimension for decoder\n",
        "  skip_encoder_pe: False # Whether to skip positional encoding for encoder\n",
        "  skip_decoder_pe: False # Whether to skip positional encoding for decoder\n",
        "\n",
        "  # Common parameters\n",
        "  dropout: 0.0          # Dropout rate\n",
        "  layer_drop_rate: 0.0  # Layer dropout rate\n",
        "  weight_tying: False   # Whether to use weight tying\n",
        "\n",
        "###### Common Training Parameters ------------------------------------------------\n",
        "training:\n",
        "  use_wandb                   : True   # Toggle wandb logging\n",
        "  wandb_run_id                : \"none\" # \"none\" or \"run_id\"\n",
        "  resume                      : True   # Resume an existing run (run_id != 'none')\n",
        "  gradient_accumulation_steps : 1\n",
        "  wandb_project               : \"Set-Project-Name-Here\" # wandb project to log to\n",
        "\n",
        "###### Loss ----------------------------------------------------------------------\n",
        "loss: # Just good ol' CrossEntropy\n",
        "  label_smoothing: 0.0\n",
        "  ctc_weight: 0.2\n",
        "\n",
        "###### Optimizer -----------------------------------------------------------------\n",
        "optimizer:\n",
        "  name: \"adamw\" # Options: sgd, adam, adamw\n",
        "  lr: 0.0004    # Base learning rate\n",
        "\n",
        "  # Common parameters\n",
        "  weight_decay: 0.000001\n",
        "\n",
        "  # Parameter groups\n",
        "  # You can add more param groups as you want and set their learning rates and patterns\n",
        "  param_groups:\n",
        "    - name: self_attn\n",
        "      patterns: []  # Will match all parameters containing \"encoder\"\n",
        "      lr: 0.0002    # LR for self_attn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "    - name: ffn\n",
        "      patterns: []\n",
        "      lr: 0.0002  # LR for ffn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "  # Layer-wise learning rates\n",
        "  layer_decay:\n",
        "    enabled: False\n",
        "    decay_rate: 0.75\n",
        "\n",
        "  # SGD specific parameters\n",
        "  sgd:\n",
        "    momentum: 0.9\n",
        "    nesterov: True\n",
        "    dampening: 0\n",
        "\n",
        "  # Adam specific parameters\n",
        "  adam:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "  # AdamW specific parameters\n",
        "  adamw:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "###### Scheduler -----------------------------------------------------------------\n",
        "scheduler:\n",
        "  name: \"cosine\"  # Options: reduce_lr, cosine, cosine_warm\n",
        "\n",
        "  # ReduceLROnPlateau specific parameters\n",
        "  reduce_lr:\n",
        "    mode: \"min\"  # Options: min, max\n",
        "    factor: 0.1  # Factor to reduce learning rate by\n",
        "    patience: 10  # Number of epochs with no improvement after which LR will be reduced\n",
        "    threshold: 0.0001  # Threshold for measuring the new optimum\n",
        "    threshold_mode: \"rel\"  # Options: rel, abs\n",
        "    cooldown: 0  # Number of epochs to wait before resuming normal operation\n",
        "    min_lr: 0.0000001  # Minimum learning rate\n",
        "    eps: 1e-8  # Minimal decay applied to lr\n",
        "\n",
        "  # CosineAnnealingLR specific parameters\n",
        "  cosine:\n",
        "    T_max: 15  # Maximum number of iterations\n",
        "    eta_min: 0.0000001  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # CosineAnnealingWarmRestarts specific parameters\n",
        "  cosine_warm:\n",
        "    T_0: 10    # Number of iterations for the first restart\n",
        "    T_mult: 10 # Factor increasing T_i after each restart\n",
        "    eta_min: 0.0000001  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # Warmup parameters (can be used with any scheduler)\n",
        "  warmup:\n",
        "    enabled: True\n",
        "    type: \"exponential\"  # Options: linear, exponential\n",
        "    epochs: 5\n",
        "    start_factor: 0.1\n",
        "    end_factor: 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycLt56sWXWXz"
      },
      "outputs": [],
      "source": [
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8X3BcuXWXz"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gstAD2BGXWXz"
      },
      "outputs": [],
      "source": [
        "Tokenizer = H4Tokenizer(\n",
        "    token_map  = config['tokenization']['token_map'],\n",
        "    token_type = config['tokenization']['token_type']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hCLVwnaXWXz"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwmZydebXWXz"
      },
      "outputs": [],
      "source": [
        "train_dataset = ASRDataset(\n",
        "    partition=config['data']['train_partition'],\n",
        "    config=config['data'],\n",
        "    tokenizer=Tokenizer,\n",
        "    isTrainPartition=True,\n",
        "    global_stats=None  # Will compute stats from training data\n",
        ")\n",
        "\n",
        "# TODO: Get the computed global stats from training set\n",
        "global_stats = None\n",
        "if config['data']['norm'] == 'global_mvn':\n",
        "    global_stats = (train_dataset.global_mean, train_dataset.global_std)\n",
        "    print(f\"Global stats computed from training set.\")\n",
        "\n",
        "val_dataset = ASRDataset(\n",
        "    partition=config['data']['val_partition'],\n",
        "    config=config['data'],\n",
        "    tokenizer=Tokenizer,\n",
        "    isTrainPartition=False,\n",
        "    global_stats=global_stats\n",
        ")\n",
        "\n",
        "test_dataset = ASRDataset(\n",
        "    partition=config['data']['test_partition'],\n",
        "    config=config['data'],\n",
        "    tokenizer=Tokenizer,\n",
        "    isTrainPartition=False,\n",
        "    global_stats=global_stats\n",
        ")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAFMrdMLXWXz"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGRynmFPXWXz"
      },
      "outputs": [],
      "source": [
        "train_loader    = DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = True,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = train_dataset.collate_fn\n",
        ")\n",
        "\n",
        "val_loader      = DataLoader(\n",
        "    dataset     = val_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = val_dataset.collate_fn\n",
        ")\n",
        "\n",
        "test_loader     = DataLoader(\n",
        "    dataset     = test_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = test_dataset.collate_fn\n",
        ")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YILqrSuXWX0"
      },
      "source": [
        "### Dataloader Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awodg0EWXWX0"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPNijuHBXWX0"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYjQOBj2XWX0"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8_T2fH3XWX0"
      },
      "source": [
        "## Calculate Max Lengths\n",
        "Calculating the maximum transcript length across your dataset is a crucial step when working with certain transformer models.\n",
        "-  We'll use sinusoidal positional encodings that must be precomputed up to a fixed maximum length.\n",
        "- This maximum length is a hyperparameter that determines:\n",
        "  - How long of a sequence your model can process\n",
        "  - The size of your positional encoding matrix\n",
        "  - Memory requirements during training and inference\n",
        "- `Requirements`: For this assignment, ensure your positional encodings can accommodate at least the longest sequence in your dataset to prevent truncation. However, you can set this value higher if you anticipate using your languagemodel to work with longer sequences in future tasks (hint: this might be useful for P2! ðŸ˜‰).\n",
        "- `NOTE`: We'll be using the same positional encoding matrix for all sequences in your dataset. Take this into account when setting your maximum length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guY_wgFjXWX0"
      },
      "outputs": [],
      "source": [
        "max_feat_len       = max(train_dataset.feat_max_len, val_dataset.feat_max_len, test_dataset.feat_max_len)\n",
        "max_transcript_len = max(train_dataset.text_max_len, val_dataset.text_max_len, test_dataset.text_max_len)\n",
        "max_len            = max(max_feat_len, max_transcript_len)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Max Feature Length':<30} : {max_feat_len}\")\n",
        "print(f\"{'Max Transcript Length':<30} : {max_transcript_len}\")\n",
        "print(f\"{'Overall Max Length':<30} : {max_len}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmryM_AHXWX0"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fEQ0Ns_XWX0"
      },
      "outputs": [],
      "source": [
        "wandb.login(key=\"31888e0ba72a18d4a57ea02c19a9687bc4481f37\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXcjkHQ_XWX0"
      },
      "source": [
        "## Training\n",
        "Every time you run the trainer, it will create a new directory in the `expts` folder with the following structure:\n",
        "```\n",
        "expts/\n",
        "    â””â”€â”€ {run_name}/\n",
        "        â”œâ”€â”€ config.yaml\n",
        "        â”œâ”€â”€ model_arch.txt\n",
        "        â”œâ”€â”€ checkpoints/\n",
        "        â”‚   â”œâ”€â”€ checkpoint-best-metric-model.pth\n",
        "        â”‚   â””â”€â”€ checkpoint-last-epoch-model.pth\n",
        "        â”œâ”€â”€ attn/\n",
        "        â”‚   â””â”€â”€ {attention visualizations}\n",
        "        â””â”€â”€ text/\n",
        "            â””â”€â”€ {generated text outputs}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS7fwKk5XWX0"
      },
      "source": [
        "### Training Strategy 1: Cold-Start Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-y9NyN4XWX0"
      },
      "source": [
        "#### Model Load (Default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTSjyngVXWX0"
      },
      "outputs": [],
      "source": [
        "model_config = config['model'].copy()\n",
        "model_config.update({\n",
        "    'max_len': max_len,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "\n",
        "model = EncoderDecoderTransformer(**model_config)\n",
        "\n",
        "# Get some inputs from the train dataloader\n",
        "for batch in train_loader:\n",
        "    padded_feats, padded_shifted, padded_golden, feat_lengths, transcript_lengths = batch\n",
        "    break\n",
        "\n",
        "\n",
        "model_stats = summary(model, input_data=[padded_feats, padded_shifted, feat_lengths, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN6wc57eXWX1"
      },
      "source": [
        "#### Initialize Trainer\n",
        "\n",
        "If you need to reload the model from a checkpoint, you can do so by calling the `load_checkpoint` method.\n",
        "\n",
        "```python\n",
        "checkpoint_path = \"path/to/checkpoint.pth\"\n",
        "trainer.load_checkpoint(checkpoint_path)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eg-NsHzXWX1"
      },
      "outputs": [],
      "source": [
        "trainer = ASRTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"add_run_name\",\n",
        "    config_file=\"config.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiQSYD7jXWX1"
      },
      "source": [
        "### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_IQUFhmXWX1"
      },
      "source": [
        "#### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1mMBVjrXWX1"
      },
      "outputs": [],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h4o2qWEXWX1"
      },
      "source": [
        "#### Creating a test scheduler and plotting the learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilPlvS6EXWX1"
      },
      "outputs": [],
      "source": [
        "test_scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")\n",
        "\n",
        "plot_lr_schedule(\n",
        "    scheduler=test_scheduler,\n",
        "    num_epochs=20,\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1qQK403XWX1"
      },
      "source": [
        "#### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3-MTweSXWX2"
      },
      "outputs": [],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y3ASKqWXWX2"
      },
      "source": [
        "#### Train\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKCzg3U8XWX2"
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9o7QclnXWX2"
      },
      "source": [
        "#### Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the recognition config: Greedy search\n",
        "recognition_config = {\n",
        "    'num_batches': None,\n",
        "    'temperature': 1.0,\n",
        "    'repeat_penalty': 1.0,\n",
        "    'lm_weight': None,\n",
        "    'lm_model': None,\n",
        "    'beam_width': 1, # Beam width of 1 reverts to greedy\n",
        "}\n",
        "\n",
        "# Recognize with the shallow fusion config\n",
        "config_name = \"test\"\n",
        "print(f\"Evaluating with {config_name} config\")\n",
        "results = trainer.recognize(test_loader, recognition_config, config_name=config_name, max_length=max_transcript_len)\n",
        "\n",
        "\n",
        "# Calculate metrics on full batch\n",
        "generated = [r['generated'] for r in results]\n",
        "results_df = pd.DataFrame(\n",
        "    {\n",
        "        'id': range(len(generated)),\n",
        "        'transcription': generated\n",
        "    }\n",
        ")\n",
        "\n",
        "# Cleanup (Will end wandb run)\n",
        "trainer.cleanup()"
      ],
      "metadata": {
        "id": "bmtZ3E46N0Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Submit to Kaggle"
      ],
      "metadata": {
        "id": "Srfle5jUeGYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head()"
      ],
      "metadata": {
        "id": "jFRZqdazOfZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"results.csv\", index=False)\n",
        "!kaggle competitions submit -c 11785-s25-hw4p2-asr -f results.csv -m \"Testing\""
      ],
      "metadata": {
        "id": "bqWwBD6kO0Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Cx3nH2XWX3"
      },
      "source": [
        "### Training Strategy 2: Progressive Trainer\n",
        "\n",
        "In this mode of training, you can start with a model with only 1 encoder and 1 decoder layer, and then increase the number of layers after every pre-train iteration, optionally freezing the previous layers and scheduling regularization such as dropout  and label smoothing, which you will keep low or disabled initially and then later enable. Finally, you will unfreeze all layers and train the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr8VqVWvXWX3"
      },
      "source": [
        "#### Model Load (Default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGadpsIfXWX3"
      },
      "outputs": [],
      "source": [
        "model_config = config['model'].copy()\n",
        "model_config.update({\n",
        "    'max_len': max_len,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "\n",
        "model = EncoderDecoderTransformer(**model_config)\n",
        "\n",
        "# Get some inputs from the train dataloader\n",
        "for batch in train_loader:\n",
        "    padded_feats, padded_shifted, padded_golden, feat_lengths, transcript_lengths = batch\n",
        "    break\n",
        "\n",
        "\n",
        "model_stats = summary(model, input_data=[padded_feats, padded_shifted, feat_lengths, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slF3vnA7XWX3"
      },
      "source": [
        "#### Initialize Progressive Trainer\n",
        "\n",
        "If you need to reload the model from a checkpoint, you can do so by calling the `load_checkpoint` method.\n",
        "\n",
        "```python\n",
        "checkpoint_path = \"path/to/checkpoint.pth\"\n",
        "trainer.load_checkpoint(checkpoint_path)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M9Q4UvjXWX3"
      },
      "outputs": [],
      "source": [
        "trainer = ProgressiveTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"add_run_name\",\n",
        "    config_file=\"config.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG7H57rCXWX3"
      },
      "source": [
        "#### Define your training stages\n",
        "The `ProgressiveTrainer` class implements a curriculum learning approach where model complexity and regularization are gradually increased through defined training stages.\n",
        "\n",
        "##### Stage Configuration\n",
        "\n",
        "Each stage is defined as a dictionary with the following parameters:\n",
        "```python\n",
        "{\n",
        "    'name': str,                        # Name of the training stage\n",
        "    'epochs': int,                      # Number of epochs to train in this stage\n",
        "    'encoder_active_layers': List[int], # Which encoder layers to use\n",
        "    'decoder_active_layers': List[int], # Which decoder layers to use\n",
        "    'encoder_freeze': List[bool],       # Whether to freeze each encoder layer\n",
        "    'decoder_freeze': List[bool],       # Whether to freeze each decoder layer\n",
        "    'dropout': float,                   # Dropout rate for this stage\n",
        "    'label_smoothing': float,           # Label smoothing value\n",
        "    'data_subset': float                # Fraction of training data to use (0.0-1.0)\n",
        "}\n",
        "```\n",
        "\n",
        "It is best understood by an example. Here is a breakdown of the stages defined below for a model with 6 encoder and 6 decoder layers:\n",
        "\n",
        "- `Initial (1 layers)`:\n",
        "   - This stage starts with a model with only 1 encoder and 1 decoder layer.\n",
        "   - No freezing or regularization is applied.\n",
        "   - It uses 20% of the training data.\n",
        "- `2 layers`:\n",
        "   - This stage increases the number of layers to 2 for both the encoder and decoder.\n",
        "   - The previous layer (encoder layer 1 and decoder layer 1) are frozen.\n",
        "   - No regularization is applied.\n",
        "   - It uses 20% of the training data.\n",
        "- `4 layers`:\n",
        "   - This stage increases the number of layers to 4 for both the encoder and decoder.\n",
        "   - The previous layers (encoder layers 1 and 2 and decoder layers 1 and 2) are frozen.\n",
        "   - Dropout is set to 0.05 and label smoothing is set to 0.0.\n",
        "   - It uses 20% of the training data.\n",
        "- `All 6 layers`:\n",
        "   - This stage uses all 6 encoder and 6 decoder layers.\n",
        "   - The 4 previous layers are frozen and the last 2 layers are trained.\n",
        "   - Dropout is set to 0.1 and label smoothing is set to 0.0.\n",
        "   - It uses 20% of the training data.\n",
        "- `Final (with label smoothing)`:\n",
        "   - This stage uses all 6 encoder and 6 decoder layers.\n",
        "   - All layers are unfrozen and trained.\n",
        "   - Dropout is set to 0.1 and label smoothing is set to 0.1.\n",
        "   - It uses 20% of the training data.    \n",
        "\n",
        "Define your stages here. Also, the active_layers do not have to be contiguous. For example, for stage 2, you could have had layer 1 and 6 as active layers.\n",
        "\n",
        "##### Important Notes\n",
        "- Ensure `encoder_freeze` and `decoder_freeze` lists match the length of their respective `active_layers`\n",
        "- `data_subset` should be between 0 and 1\n",
        "- Stage transitions are handled automatically by the trainer\n",
        "- The same optimizer and scheduler are used for all stages so keep that in mind while setting the learning rates and other parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BAOTge3XWX4"
      },
      "outputs": [],
      "source": [
        "## Example with a model with 6 encoder and 6 decoder layers\n",
        "stages = [\n",
        "            {\n",
        "                'name': 'Initial (2 Encoder + 1 Decoder layers)',\n",
        "                'epochs': 5,\n",
        "                'encoder_active_layers': list(range(2)),\n",
        "                'decoder_active_layers': list(range(1)),\n",
        "                'encoder_freeze': [False, False],\n",
        "                'decoder_freeze': [False],\n",
        "                'dropout': 0.0,\n",
        "                'label_smoothing': 0.0,\n",
        "                'data_subset': 0.4\n",
        "            },\n",
        "            {\n",
        "                'name': '4 Encoder + 2 Decoder layers',\n",
        "                'epochs': 5,\n",
        "                'encoder_active_layers': list(range(4)),\n",
        "                'decoder_active_layers': list(range(2)),\n",
        "                'encoder_freeze': [True, True, False, False],\n",
        "                'decoder_freeze': [True, False],\n",
        "                'dropout': 0.0,\n",
        "                'label_smoothing': 0.0,\n",
        "                'data_subset': 0.4\n",
        "            },\n",
        "            {\n",
        "                'name': '8 Encoder + 4 Decoder layers',\n",
        "                'epochs': 5,\n",
        "                'encoder_active_layers': list(range(8)),\n",
        "                'decoder_active_layers': list(range(4)),\n",
        "                'encoder_freeze': [True, True, True, True, False, False, False, False],\n",
        "                'decoder_freeze': [True, True, False, False],\n",
        "                'dropout': 0.05,\n",
        "                'label_smoothing': 0.0,\n",
        "                'data_subset': 0.4\n",
        "            },\n",
        "            {\n",
        "                'name': '10 Encoder + 6 Decoder layers',\n",
        "                'epochs': 5,\n",
        "                'encoder_active_layers': list(range(12)),\n",
        "                'decoder_active_layers': list(range(6)),\n",
        "                'encoder_freeze': [True, True, True, True, True, True, True, True, False, False, False, False],\n",
        "                'decoder_freeze': [True, True, True, True, False, False],\n",
        "                'dropout': 0.1,\n",
        "                'label_smoothing': 0.0,\n",
        "                'data_subset': 0.4\n",
        "            },\n",
        "            {\n",
        "                'name': 'Final (with label smoothing)',\n",
        "                'epochs': 5,\n",
        "                'encoder_active_layers': list(range(12)),\n",
        "                'decoder_active_layers': list(range(6)),\n",
        "                'encoder_freeze': [False, False, False, False, False, False, False, False, False, False, False, False],\n",
        "                'decoder_freeze': [False, False, False, False, False, False],\n",
        "                'dropout': 0.1,\n",
        "                'label_smoothing': 0.1,\n",
        "                'data_subset': 0.4\n",
        "            }\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrmQf9j5XWX4"
      },
      "source": [
        "#### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdAZaqu_XWX4"
      },
      "source": [
        "##### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jqfqnYCXWX4"
      },
      "outputs": [],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAe_izRxXWX4"
      },
      "source": [
        "##### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmd7s9SJXWX4"
      },
      "outputs": [],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1RxwPhtXWX4"
      },
      "source": [
        "#### Train Progressively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDc-8Tw6XWX4"
      },
      "outputs": [],
      "source": [
        "trainer.progressive_train(train_loader, val_loader, stages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKXnxUINXWX5"
      },
      "source": [
        "#### Unfreeze all layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK6Zi8i3XWX5"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiqi_O4UXWX5"
      },
      "source": [
        "#### Re-load Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZI7QV1pXWX5"
      },
      "source": [
        "##### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKkRRcTJXWX5"
      },
      "outputs": [],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NPotBmyXWX5"
      },
      "source": [
        "##### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJaaQXUiXWX5"
      },
      "outputs": [],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPOyadolXWX5"
      },
      "source": [
        "#### Train Full\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAkF3h0_XWX5"
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1astxnD1fLQZ"
      },
      "source": [
        "#### Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the recognition config: Greedy search\n",
        "recognition_config = {\n",
        "    'num_batches': None,\n",
        "    'temperature': 1.0,\n",
        "    'repeat_penalty': 1.0,\n",
        "    'lm_weight': None,\n",
        "    'lm_model': None,\n",
        "    'beam_width': 1, # Beam width of 1 reverts to greedy\n",
        "}\n",
        "\n",
        "# Recognize with the shallow fusion config\n",
        "config_name = \"test\"\n",
        "print(f\"Evaluating with {config_name} config\")\n",
        "results = trainer.recognize(test_loader, recognition_config, config_name=config_name, max_length=max_transcript_len)\n",
        "\n",
        "\n",
        "# Calculate metrics on full batch\n",
        "generated = [r['generated'] for r in results]\n",
        "results_df = pd.DataFrame(\n",
        "    {\n",
        "        'id': range(len(generated)),\n",
        "        'transcription': generated\n",
        "    }\n",
        ")\n",
        "\n",
        "# Cleanup (Will end wandb run)\n",
        "trainer.cleanup()"
      ],
      "metadata": {
        "id": "iV0O69tAfLQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Submit to Kaggle"
      ],
      "metadata": {
        "id": "DOi4qPISfLQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head()"
      ],
      "metadata": {
        "id": "EE6f8zJlfLQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"results.csv\", index=False)\n",
        "!kaggle competitions submit -c 11785-s25-hw4p2-asr -f results.csv -m \"Testing\""
      ],
      "metadata": {
        "id": "XiZoJ_KBfLQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKzhcFPXWX6"
      },
      "source": [
        "### Training Strategy 3: Pretrained Decoder Initialized\n",
        "\n",
        "In this mode of training, you can:\n",
        "- Initialize the Encoder-Decoder Transformer with the shared weights from a pretrained Decoder-Only Transformer (self-attn's, ffn's, etc).\n",
        "- You will then first freeze these pre-trained weights and train the encoder and just the cross-attention decoder layers on the ASR task.\n",
        "- After that, you will unfreeze all weights and train the model, optionally setting a lower learning rate for the pre-trained weights.\n",
        "\n",
        "`NOTE`: You can get a bit adventurous if you'd like, for ex, combining this with the progressive training strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeOeqcljXWX6"
      },
      "source": [
        "#### Decoder-Only Initialized Load\n",
        "\n",
        "- Be sure to set the `decoder_checkpoint` below to the path of the `COMPATIBLE` decoder checkpoint you trained during your `HW4P1` ablation study.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AViBt0sfXWX6"
      },
      "outputs": [],
      "source": [
        "model_config = config['model'].copy()\n",
        "\n",
        "# TODO: Set the path to the decoder checkpoint.\n",
        "decoder_checkpoint = \"path/to/decoder_checkpoint.pth\"\n",
        "model_config.update({\n",
        "    'max_len': max_len,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "\n",
        "model, param_info = EncoderDecoderTransformer.from_pretrained_decoder(\n",
        "    decoder_checkpoint_path=decoder_checkpoint,\n",
        "    config=model_config,\n",
        ")\n",
        "\n",
        "# Get some inputs from the train dataloader\n",
        "for batch in train_loader:\n",
        "    padded_feats, padded_shifted, padded_golden, feat_lengths, transcript_lengths = batch\n",
        "    break\n",
        "\n",
        "\n",
        "model_stats = summary(model, input_data=[padded_feats, padded_shifted, feat_lengths, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_gP1PLvXWX6"
      },
      "source": [
        "#### Freeze Pre-trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl0uZ7UXXWX6"
      },
      "outputs": [],
      "source": [
        "transferred_params = [name for (name, _) in param_info['transferred']]\n",
        "for name, param in model.named_parameters():\n",
        "    if name in transferred_params:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abNie_PvXWX6"
      },
      "source": [
        "#### Initialize Trainer\n",
        "\n",
        "If you need to reload the model from a checkpoint, you can do so by calling the `load_checkpoint` method.\n",
        "\n",
        "```python\n",
        "checkpoint_path = \"path/to/checkpoint.pth\"\n",
        "trainer.load_checkpoint(checkpoint_path)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZHjgbBaXWX6"
      },
      "outputs": [],
      "source": [
        "trainer = ASRTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"add_run_name\",\n",
        "    config_file=\"config.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r55Xjt35XWX6"
      },
      "source": [
        "#### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwOPjdkDXWX6"
      },
      "source": [
        "##### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS6VvdxEXWX6"
      },
      "outputs": [],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4v4FSRIXWX6"
      },
      "source": [
        "##### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "548wVxLsXWX6"
      },
      "outputs": [],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA5tNadBXWX7"
      },
      "source": [
        "##### Train Encoder and Cross-Attention Decoder Layers with frozen pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzSqpgTxXWX7"
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okOzABkgXWX7"
      },
      "source": [
        "#### Unfreeze all weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qfvigXRXWX7"
      },
      "outputs": [],
      "source": [
        "transferred_params = [name for (name, _) in param_info['transferred']]\n",
        "for name, param in model.named_parameters():\n",
        "    if name in transferred_params:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Check that all parameters are being trained\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        assert param.requires_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v9qP8BBXWX7"
      },
      "source": [
        "#### Re-load Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SETYR_MjXWX7"
      },
      "source": [
        "##### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX1pFlUWXWX7"
      },
      "outputs": [],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUagY8SFXWX7"
      },
      "source": [
        "##### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI-5w5G-XWX7"
      },
      "outputs": [],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awuxKHK8XWX7"
      },
      "source": [
        "#### Train Full\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EN5olPxXWX7"
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8D-zCzGfXL1"
      },
      "source": [
        "#### Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the recognition config: Greedy search\n",
        "recognition_config = {\n",
        "    'num_batches': None,\n",
        "    'temperature': 1.0,\n",
        "    'repeat_penalty': 1.0,\n",
        "    'lm_weight': None,\n",
        "    'lm_model': None,\n",
        "    'beam_width': 1, # Beam width of 1 reverts to greedy\n",
        "}\n",
        "\n",
        "# Recognize with the shallow fusion config\n",
        "config_name = \"test\"\n",
        "print(f\"Evaluating with {config_name} config\")\n",
        "results = trainer.recognize(test_loader, recognition_config, config_name=config_name, max_length=max_transcript_len)\n",
        "\n",
        "\n",
        "# Calculate metrics on full batch\n",
        "generated = [r['generated'] for r in results]\n",
        "results_df = pd.DataFrame(\n",
        "    {\n",
        "        'id': range(len(generated)),\n",
        "        'transcription': generated\n",
        "    }\n",
        ")\n",
        "\n",
        "# Cleanup (Will end wandb run)\n",
        "trainer.cleanup()"
      ],
      "metadata": {
        "id": "nzX0iD67fXL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Submit to Kaggle"
      ],
      "metadata": {
        "id": "hT-j1CeYfXL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head()"
      ],
      "metadata": {
        "id": "bLS2BPrcfXL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"results.csv\", index=False)\n",
        "!kaggle competitions submit -c 11785-s25-hw4p2-asr -f results.csv -m \"Testing\""
      ],
      "metadata": {
        "id": "14ka40flfXL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fG4S-geXWX7"
      },
      "source": [
        "## Shallow Fusion Inference\n",
        "\n",
        "Here you can use an external language model (i.e. the one you trained in HW4P1) to potentially improve the ASR performance of your model. On a high level, each step of beam search will involve a log-linear interpolation between the ASR model's logits and the language model's logits.\n",
        "\n",
        "- Set the `path_to_lm_checkpoint` below to the path of the `COMPATIBLE` language model checkpoint you trained during your `HW4P1` ablation study. By compatible, we mean that the tokenization type should match the tokenizer used in the ASR model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvzCzN7OXWX7"
      },
      "outputs": [],
      "source": [
        "# NOTE: The tokenization type should match the tokenizer used in the ASR model.\n",
        "path_to_lm_checkpoint = \"path_to_lm_checkpoint.pth\"\n",
        "\n",
        "# Load the LM checkpoint\n",
        "lm_dict = torch.load(path_to_lm_checkpoint, map_location=trainer.device, weights_only=True)\n",
        "\n",
        "# Get the model config\n",
        "lm_model_config = lm_dict['config']['model']\n",
        "lm_max_len = lm_dict['model_state_dict']['positional_encoding.pe'].shape[1]\n",
        "lm_model_config.update({\n",
        "    'max_len': lm_max_len,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "\n",
        "# Initialize the LM model\n",
        "lm_model = DecoderOnlyTransformer(**lm_model_config)\n",
        "\n",
        "# Get some inputs from the train dataloader\n",
        "for batch in train_loader:\n",
        "    padded_feats, padded_shifted, padded_golden, feat_lengths, transcript_lengths = batch\n",
        "    break\n",
        "\n",
        "\n",
        "model_stats = summary(lm_model, input_data=[padded_shifted, transcript_lengths])\n",
        "print(model_stats)\n",
        "\n",
        "lm_model.load_state_dict(lm_dict['model_state_dict'], strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbwvWpArXWX8"
      },
      "source": [
        "### Inference\n",
        "- Set the `lm_weight` below to determine the weight given to the LM model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVs3fZbLXWX8"
      },
      "outputs": [],
      "source": [
        "\n",
        "lm_weight = 0.5 # TODO: Set the weight for the LM model\n",
        "\n",
        "# Define the recognition config: Beam search with width 10 + LM blending\n",
        "recognition_config = {\n",
        "    'num_batches': None,\n",
        "    'temperature': 1.0,\n",
        "    'repeat_penalty': 1.0,\n",
        "    'lm_weight': lm_weight,\n",
        "    'lm_model': lm_model,\n",
        "    'beam_width': 10,\n",
        "}\n",
        "\n",
        "# Recognize with the shallow fusion config\n",
        "config_name = \"shallow-fusion\"\n",
        "print(f\"Evaluating with {config_name} config\")\n",
        "results = trainer.recognize(test_loader, recognition_config, config_name=config_name, max_length=min(max_transcript_len, lm_max_len))\n",
        "\n",
        "\n",
        "# Calculate metrics on full batch\n",
        "generated = [r['generated'] for r in results]\n",
        "results_df = pd.DataFrame(\n",
        "    {\n",
        "        'id': range(len(generated)),\n",
        "        'transcription': generated\n",
        "    }\n",
        ")\n",
        "\n",
        "# Cleanup (Will end wandb run)\n",
        "trainer.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Submit to Kaggle"
      ],
      "metadata": {
        "id": "RuLBBtXPfdf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head()"
      ],
      "metadata": {
        "id": "-8wXo2lJfdf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"results.csv\", index=False)\n",
        "!kaggle competitions submit -c 11785-s25-hw4p2-asr -f results.csv -m \"Testing\""
      ],
      "metadata": {
        "id": "6zU6XLZufdf8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "T1K8ZJzQXWXm",
        "dqzcpqG0XWXp",
        "uP0Aucc7XWXs",
        "k5ey-Nd0XWXx"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}