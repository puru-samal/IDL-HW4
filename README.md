# Setup

Create Conda Environment (Both PSC and Local)

```bash
# Create Conda Environment
module load anaconda # PSC only
conda create -n your_env_name python=3.12.4

# Deactivate Conda Environment
conda deactivate

# Activate Conda Environment
conda activate your_env_name

# Install Dependencies
pip install -r requirements.txt
```

# PSC Instructions

Load the anaconda module:

```bash
# Load the anaconda module
module load anaconda

# Activate Conda Environment
conda activate your_env_name

# Start an 8 hour interact session:
interact -p GPU-shared --gres=gpu:v100-32:1 -t 8:00:00
```

Note: Sometimes PSC automatically reverts to the default environment (`base`). If this happens, you can deactivate the default environment and activate your environment again with:

```bash
conda deactivate
conda activate your_env_name
```

`Optional`: Open a `tmux` session:

```bash
tmux new -s your_session_name
```

`Optional`: Download the dataset into the node's `$LOCAL` directory for faster disk access (storage is not persistent):

```bash
cd $LOCAL
python download_data.py
tar -xvzf hw4_data.tar.gz
rm hw4_data.tar.gz
cd path/to/project
```

# HW4 Handout Directory Structure

This should be the directory structure from your projectroot directory:

## ðŸ““ Notebooks & Core Files

```
.
â”œâ”€â”€ HW4P1_nb.ipynb
â”œâ”€â”€ HW4P2_nb.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile
â”œâ”€â”€ autograde-Makefile
â”œâ”€â”€ simulate_autolab.py
â””â”€â”€ autograde.tar

```

## ðŸ“Š Dataset Structure

```

hw4_data_subset/
â”œâ”€â”€ hw4p1_data/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ valid/
â”‚ â””â”€â”€ test/
â””â”€â”€ hw4p2_data/
â”œâ”€â”€ dev-clean/
â”‚ â”œâ”€â”€ fbank/
â”‚ â””â”€â”€ text/
â”œâ”€â”€ test-clean/
â”‚ â”œâ”€â”€ fbank/
â”‚ â””â”€â”€ text/
â””â”€â”€ train-clean-100/
â”œâ”€â”€ fbank/
â””â”€â”€ text/

```

## ðŸ”§ Implementation Files

### Main Library (hw4lib/)

```

hw4lib/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ tokenizer_jsons/
â”‚ â”œâ”€â”€ asr_dataset.py
â”‚ â”œâ”€â”€ lm_dataset.py
â”‚ â””â”€â”€ tokenizer.py
â”œâ”€â”€ decoding/
â”‚ â””â”€â”€ sequence_generator.py
â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ masks.py
â”‚ â”œâ”€â”€ positional_encoding.py
â”‚ â”œâ”€â”€ speech_embedding.py
â”‚ â”œâ”€â”€ sublayers.py
â”‚ â”œâ”€â”€ decoder_layers.py
â”‚ â”œâ”€â”€ encoder_layers.py
â”‚ â””â”€â”€ transformers.py
â””â”€â”€ trainers/
â”œâ”€â”€ base_trainer.py
â”œâ”€â”€ asr_trainer.py
â””â”€â”€ lm_trainer.py

```

### MyTorch Library Components (mytorch/)

```

mytorch/nn/
â”œâ”€â”€ activation.py
â”œâ”€â”€ linear.py
â”œâ”€â”€ scaled_dot_product_attention.py
â””â”€â”€ multi_head_attention.py

```

### Test Suite (tests/)

```

tests/
â”œâ”€â”€ testing_framework.py
â”œâ”€â”€ test_mytorch*.py
â”œâ”€â”€ test_dataset*.py
â”œâ”€â”€ test_mask*.py
â”œâ”€â”€ test_positional_encoding.py
â”œâ”€â”€ test_sublayers*.py
â”œâ”€â”€ test_encoderlayers*.py
â”œâ”€â”€ test_decoderlayers*.py
â”œâ”€â”€ test_transformers\*.py
â”œâ”€â”€ test_hw4p1.py
â””â”€â”€ test_decoding.py

```

# TODO:

- [ ] Remove `tests/test_hw4p1.py` from the handout
- [ ] Update threshold in `tests/test_hw4p1.py` and re-run `make create_autograde`
- [ ] Replace autolab's `autograde.tar` after threshold is updated
